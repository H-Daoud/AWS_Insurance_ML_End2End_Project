ğŸš— **HUK-COBURG Feedback Intelligence (Prototyp)**
âš¡ **A Compound AI System Hybrid ML (DistilBERT) + RAG (Azure OpenAI)**
**Pipeline:** `Local ML (Router)` â” `RAG (Policy Engine)` â” `LLM (Reasoning)`

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Azure](https://img.shields.io/badge/Cloud-Azure-0078D4?logo=microsoftazure)
![Model](https://img.shields.io/badge/Router-DistilBERT-yellow)
![GenAI](https://img.shields.io/badge/Reasoning-OpenAI-green?logo=openai)
![Status](https://img.shields.io/badge/Status-Prototype-orange)
![DevOps](https://img.shields.io/badge/MLOps-red)

<p align="center">
  <img src="https://github.com/Dianarittershofer/CC_Hassan_Daoud/blob/main/docs/Architecture.png" alt="Azure Architecture Diagram" width="800">
</p>

---

# NOTE: This project now uses AWS as the primary cloud infrastructure. Any references to Azure (e.g., Azure OpenAI, Azure ML, Azure-specific Terraform templates, or Azure deployment scripts) are deprecated and should be ignored for current and future deployments. All instructions, diagrams, and documentation should focus on AWS resources, workflows, and best practices.

---

ğŸš€ **ProjektÃ¼bersicht**
Dieses Projekt demonstriert ein Compound AI System (Zusammengesetztes KI-System), das entwickelt wurde, um komplexe Kundenfeedback-Analysen fÃ¼r die HUK-COBURG zu automatisieren. Anstelle einer simplen "Blackbox"-LÃ¶sung nutzt es eine hybride Architektur: Ein lokales, kosteneffizientes ML-Modell ("Router") Ã¼bernimmt die schnelle Vorfilterung, wÃ¤hrend Azure OpenAI ("Strategist") nur fÃ¼r komplexe FÃ¤lle hinzugezogen wird. Dies optimiert Latenz und Kosten.

ğŸ¯ **Mission**
Transformation von unstrukturiertem Feedback in strukturierte GeschÃ¤ftsdaten. Ich nutze einen "Best-of-Breed"-Ansatz.
**Speed**: Lokales DistilBERT (ONNX) fÃ¼r Millisekunden-Klassifizierung.
**Intelligence**: Retrieval-Augmented Generation (RAG) fÃ¼r faktenbasiertes Reasoning.
**Compliance**: Defense-in-Depth Sicherheit (Pydantic & PII-Scrubbing) fÃ¼r DSGVO-KonformitÃ¤t.

ğŸ“‰ **Business Impact (PoC & MVP)**
**Das Problem (2025 Context)**: Die Schaden-Kosten-Quote (Combined Ratio) steht unter Druck. Die manuelle Triage von Tausenden Schadensmeldungen (FNOL) bindet wertvolle Expertenzeit. Einfache Sentiment-Analysen reichen nicht aus â€“ sie erkennen zwar dass ein Kunde wÃ¼tend ist, aber nicht warum (z.B. wegen Klausel Â§4 "Selbstbeteiligung").
**Die LÃ¶sung**: Eine Kaskadierte KI-Pipeline Das System filtert Rauschen durch lokale KI und eskaliert nur relevante FÃ¤lle an das LLM, angereichert mit Fakten aus der HUK-Wissensdatenbank.

ğŸ’° **Return on Investment (ROI)**:
1. OpEx-Optimierung (Hybrid-Ansatz): Durch den Einsatz des lokalen DistilBERT-Routers werden ca. 60% der trivialen Anfragen ohne teure OpenAI-Kosten bearbeitet. Dies senkt die Cloud-Rechnung massiv im Vergleich zu reinen LLM-LÃ¶sungen.
2. 80% Reduzierung der Triage-Zeit: Die KI liefert nicht nur das Label "Beschwerde", sondern direkt die Ursache und den Policen-Kontext. Der Sachbearbeiter muss nicht mehr suchen, sondern nur noch entscheiden.
3. Proaktive AbwanderungsprÃ¤vention (Churn Prevention): Identifiziert Muster in Beschwerden (z.B. "UnverstÃ¤ndliche KÃ¼ndigungsfristen") in Echtzeit, um gezielte RÃ¼ckgewinnungskampagnen zu steuern.
4. Defense-in-Depth Compliance: Durch die Kombination aus Input-Validierung (schemas.py) und PII-Scrubbing wird das Risiko von Data Leaks minimiert. Sensible IBANs verlassen niemals die sichere Zone.
5. KI-Halluzinations-Schutz: Die RAG-Engine verankert jede KI-Antwort in den tatsÃ¤chlichen PDF-Versicherungsbedingungen ("Ground Truth"), statt generische Antworten zu erfinden.

ğŸ—ï¸ **Systemarchitektur ("Local Twin" & Compound AI)**
Dieses Projekt implementiert eine "Local Twin"-Architektur. Es simuliert eine vollstÃ¤ndige Azure-Cloud-Umgebung lokal mittels Docker, was schnelles Prototyping ohne Cloud-Kosten ermÃ¶glicht. Das System agiert als Compound AI System (Zusammengesetztes KI-System) mit vier spezialisierten Schichten:
1. The Gatekeeper (Security & Validation Layer)
A. Funktion: Die erste Verteidigungslinie (src/main-api.py).
B. Tech: Validiert Input-Schemas via Pydantic (Anti-Injection) und bereinigt sensible PII (Namen, IBANs) mittels Regex (src/security/pii_scrubber_py), bevor Daten verarbeitet werden. 
2. The Router (Local ML Layer)
A. Funktion: Ein spezialisiertes DistilBERT-Modell (src/classifier/inference.py), das lokal als ONNX-Binary lÃ¤uft.
B. Mehrwert: Klassifiziert das Feedback in Millisekunden ohne API-Kosten. Es entscheidet, ob ein Fall komplex ist und an den "Lawyer" weitergeleitet werden muss (Triage).
3. The Lawyer (Retrieval Layer)
A. Funktion: Die RAG-Engine (src/rag/engine.py).
B. Tech: Nutzt einen pre-computed FAISS-Index (data/processed/vector_index.faiss), um in den Versicherungsbedingungen (PDF) nach Klauseln wie "Selbstbeteiligung" zu suchen. Der Index ist "immutable" und wird beim Build-Prozess erstellt.
4. The Strategist (Reasoning Layer)
A. Funktion: Der Orchestrator (src/rag/engine.py).
B. Tech: Nutzt Azure OpenAI, um die lokale Klassifizierung (Router) und die gefundenen Fakten (Lawyer) zu einer empathischen und juristisch fundierten Antwort zu synthetisieren.

ğŸ› ï¸ **Tech Stack & Engineering Standards**
1. Core & API: Python 3.10, FastAPI (High-Performance Async Backend), Streamlit (Frontend).
2. AI & Machine Learning: GenAI: OpenAI API (Reasoning & Policy Synthesis).
3. RAG Engine: FAISS (High-Speed Vector Search).
4. Classifier: ONNX Runtime (Optimized CPU Inference for DistilBERT).
5. Quality & Validation: Pydantic (Data Contracts), Pytest (Mocked Unit/Integration Tests).
6. Infrastructure & Ops: Docker (Multi-Stage Builds), Makefile (Local Automation), GitHub Actions (CI/CD).
7. Security & Compliance: Custom Regex PII Scrubber (DSGVO), API Key Middleware (Zero Trust).
8. Observability: Structured JSON Logging (Azure Monitor ready), Health Probes (Liveness checks).


**SchlÃ¼sselkomponenten**: sehe PROJECT_DOCS.md

ğŸš€ **Quick Start**
Voraussetzungen:
1. Docker (Empfohlen) ODER Python 3.10+
2. Ein OpenAI API Key (fÃ¼r die RAG/GenAI-Funktionen)

**Option 1: AusfÃ¼hren via Makefile (Empfohlen fÃ¼r Dev)**
1. Umgebung einrichten: Anstatt einer .env im Root, nutzen wir strukturierte Configs. Erstell die Dev-Konfiguration:
Bash
echo "OPENAI_API_KEY=sk-..." > configs/dev.env   # WICHTIG: Datei muss in configs/ liegen, damit src/utils.py sie findet

2. AbhÃ¤ngigkeiten installieren:
Bash
make install

3. Daten-Ingestion (ETL) ausfÃ¼hren: Bevor die App startet, muss der Vektor-Index fÃ¼r die RAG-Engine berechnet werden.
Bash
make ingest #Liest PDF aus data/raw -> Speichert Index in data/processed

4. App starten:
Bash
make run      # Startet FastAPI/Streamlit

**Option 2: AusfÃ¼hren via Docker (Produktions-Simulation)**
Erstellen eines Docker-Images und das anschlieÃŸende Bereitstellen dieses Images in ACI Azure Container Instances Das Dockerfile kÃ¼mmert sich automatisch um die Ingestion.
Bash
make docker-build
make docker-run

ğŸ›¡ï¸ **Compliance & Security (Defense in Depth)**
Als VersicherungslÃ¶sung hat der Datenschutz oberste PrioritÃ¤t. Dieser Prototyp implementiert einen Privacy-by-Design-Ansatz mit vier Sicherheitslinien:
1. PII Scrubbing (Data Loss Prevention) Bevor Daten das System verlassen (z.B. zu OpenAI), entfernt die Klasse src/security/pii_scrubber.py sensible Informationen mittels Regex/NER:
Max Mustermann â” <PERSON>
DE89 3704... â” <IBAN>
2. Input Validation (Anti-Injection) Wir vertrauen keinem User-Input. src/schemas.py nutzt Pydantic, um strenge DatenvertrÃ¤ge zu erzwingen. Malformierte Payloads oder versuchte Prompt-Injections werden abgelehnt, bevor sie die Logik erreichen.
3. Access Control (Zero Trust) Die API ist nicht Ã¶ffentlich. Die Middleware src/security/auth.py prÃ¼ft bei jeder Anfrage den API-Key im Header, um unbefugten Zugriff auf die Modell-Ressourcen zu verhindern.
4. Data Sovereignty (Geofencing) (In Produktion) Alle Azure-Ressourcen (Compute & OpenAI) werden auf die Region "Germany West Central" fixiert, um die Datenhoheit und nationale RechtskonformitÃ¤t (DSGVO) zu gewÃ¤hrleisten.

```bash
CC_Hassan_Daoud/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci_cd.yml             # MLOps: CI-Pipeline (Linting, Security Scan, Unit Tests)
â”œâ”€â”€ azure/                        # Cloud Infrastructure & MLOps
â”‚   â”œâ”€â”€ infrastructure.tf         # IaC: Terraform Definitionen (Simuliert)
â”‚   â”œâ”€â”€ score.py                  # Azure ML Entry Point (fÃ¼r Managed Endpoints)
â”‚   â””â”€â”€ submit_training_job.py    # Python SDK Skript: Sendet Training an Azure ML Compute Cluster
â”œâ”€â”€ configs/                      # Environment Management
â”‚   â”œâ”€â”€ dev.env                   # Local Development Configs
â”‚   â””â”€â”€ prod.env                  # Production Configs (Azure Secrets)
â”œâ”€â”€ data/                         # ğŸ†• DATA MANAGEMENT (ETL)
â”‚   â”œâ”€â”€ raw/                      # Immutable Inputs (Never modify these)
â”‚   â”‚   â”œâ”€â”€ vehicle_feedback.csv  # Trainingsdaten (Input fÃ¼r DistilBERT)
â”‚   â”‚   â””â”€â”€ insurance_terms.pdf   # Das "Wissen" fÃ¼r die RAG-Engine (Ground Truth)
â”‚   â””â”€â”€ processed/                # Generated Artifacts (Output of scripts/ingest_data.py)
â”‚       â”œâ”€â”€ .gitkeep
â”‚       â””â”€â”€ vector_index.faiss    # ğŸ†• The "Brain" of RAG (Fast Vector Search Index)
â”œâ”€â”€ docs/                         # ğŸ†• DOCUMENTATION
â”‚   â””â”€â”€ architecture.png          # Architektur-Diagramm fÃ¼r README
â”œâ”€â”€ models/                       # Model Registry (Local Cache)
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ huk_distilbert.onnx       # Quantisiertes Modell (Optimiert fÃ¼r CPU-Inference)
â”œâ”€â”€ notebooks/                    # ğŸ†• RESEARCH & EDA (Jupyter Notebooks)
â”‚   â”œâ”€â”€ 01_eda.ipynb              # Analyse: Verteilung der Feedback-Klassen & DatenqualitÃ¤t
â”‚   â””â”€â”€ 02_rag_prototyping.ipynb  # Experiment: Testen der Vektor-Suche vor der Implementierung
â”œâ”€â”€ reports/                      # ğŸ†• ARTIFACTS (Training Results)
â”‚   â””â”€â”€ figures/
â”‚       â””â”€â”€ confusion_matrix.png  # Visualisierung: Wo macht das Modell Fehler?
â”œâ”€â”€ scripts/                      # ğŸ†• DEVOPS & ETL
â”‚   â””â”€â”€ ingest_data.py            # Performance: Pre-calculate Embeddings beim Build (statt Runtime)
â”œâ”€â”€ src/                          # Application Core (Compound AI System)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main_api.py               # FastAPI Backend: Entry-Point mit Health-Checks & Request-IDs
â”‚   â”œâ”€â”€ schemas.py                # SECURITY: Pydantic Models zur Validierung von User-Input (Anti-Injection)
â”‚   â”œâ”€â”€ utils.py                  # OBSERVABILITY: Central Config, JSON Logging & Performance Timing
â”‚   â”œâ”€â”€ exceptions.py             # RESILIENCE: Custom Exceptions (e.g., PolicyNotFound, PIIViolation)
â”‚   â”œâ”€â”€ classifier/               # Komponente 1 - Der "Router" (Lokales ML)
â”‚   â”‚   â”œâ”€â”€ train.py              # Logik: Fine-Tuning von DistilBERT mit PyTorch
â”‚   â”‚   â”œâ”€â”€ evaluate.py           # Logik: Berechnet F1-Score & Confusion Matrix
â”‚   â”‚   â”œâ”€â”€ export_onnx.py        # Logik: Konvertiert PyTorch -> ONNX (fÃ¼r Speed/Kosten)
â”‚   â”‚   â””â”€â”€ inference.py          # Runtime: LÃ¤dt ONNX-Modell und klassifiziert Input
â”‚   â”œâ”€â”€ rag/                      # Komponente 2 - Die "Intelligence" (Azure OpenAI)
â”‚   â”‚   â”œâ”€â”€ cache.py              # SCALABILITY: Semantisches Caching hÃ¤ufiger Fragen (Spart OpenAI Kosten)
â”‚   â”‚   â”œâ”€â”€ engine.py             # Logik: RAG-Flow (Retrieve -> Augment -> Generate)
â”‚   â”‚   â””â”€â”€ vector_store.py       # Logik: Chunking der PDF & Vektor-Suche (FAISS)
â”‚   â””â”€â”€ security/                 # Komponente 3 - Die "Firewall"
â”‚       â”œâ”€â”€ auth.py               # SECURITY: API Key Middleware (Verhindert unbefugten Zugriff)
â”‚       â””â”€â”€ pii_scrubber.py       # Privacy: Entfernt IBAN/Namen via Regex vor Cloud-Transfer
â”œâ”€â”€ streamlit_app/                # Frontend (Demo UI)
â”‚   â””â”€â”€ app.py                    # User Interface: Chatbot & Dashboard Visualisierung
â”œâ”€â”€ tests/                        # Quality Assurance (Pytest)
â”‚   â”œâ”€â”€ conftest.py               # FIXTURES: Mocks fÃ¼r Azure/OpenAI (Verhindert echte API-Calls im Test)
â”‚   â”œâ”€â”€ test_classifier.py        # Unit Test: Funktioniert das ONNX-Modell?
â”‚   â”œâ”€â”€ test_rag.py               # Integration Test: Findet RAG die richtigen PDF-AbsÃ¤tze?
â”‚   â””â”€â”€ test_security.py          # Security Test: Werden IBANs zuverlÃ¤ssig gelÃ¶scht?
â”œâ”€â”€ .gitignore                    # Exclude: venv, .env, __pycache__, data/*.csv
â”œâ”€â”€ Dockerfile                    # Deployment: Multi-Stage Build (App + ONNX Modell)
â”œâ”€â”€ Makefile                      # Automation: `make train`, `make run`, `make deploy`
â”œâ”€â”€ pyproject.toml                # ğŸ†• MODERN STANDARDS: Ersetzt/ErgÃ¤nzt requirements.txt fÃ¼r Tools wie Ruff/Poetry
â”œâ”€â”€ README.md                     # Documentation: Architecture & Business Case
â””â”€â”€ requirements.txt              # Dependencies: torch, transformers, onnxruntime, openai, fastapi
ğŸ‘¨â€ğŸ’» Autor
Hassan Daoud