ğŸš— **HUK-COBURG Feedback Intelligence (Prototyp)**
âš¡ **A Compound AI System Hybrid ML (DistilBERT) + RAG (Azure OpenAI)**
**Pipeline:** `Local ML (Router)` â” `RAG (Policy Engine)` â” `LLM (Reasoning)`

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Azure](https://img.shields.io/badge/Cloud-Azure-0078D4?logo=microsoftazure)
![Model](https://img.shields.io/badge/Router-DistilBERT-yellow)
![GenAI](https://img.shields.io/badge/Reasoning-OpenAI-green?logo=openai)
![Status](https://img.shields.io/badge/Status-Prototype-orange)
![DevOps](https://img.shields.io/badge/MLOps-red)

<p align="center">
  <img src=" " width="800">
</p>
---
ğŸš€ **Projekct overview**
To create a scalable, secure, and low-latency Rest API service that provides Insurance customers with instant, context-aware answers to policy, claim, and service questions by retrieving data from internal PDF documents.

```bash
AWS_Insurance_ML_End2End_Project/
â”œâ”€â”€ aws/                  # AWS Infrastructure as Code (Terraform, CloudFormation)
â”‚   â”œâ”€â”€ cloudformation.yaml
â”‚   â”œâ”€â”€ ecr.tf
â”‚   â”œâ”€â”€ ecs.tf
â”‚   â”œâ”€â”€ infrastructure.tf
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ network.tf
â”‚   â”œâ”€â”€ score.py
â”‚   â”œâ”€â”€ secrets.tf
â”‚   â”œâ”€â”€ security.tf
â”‚   â”œâ”€â”€ submit_training_job.py
â”‚   â”œâ”€â”€ terraform.tfstate
â”‚   â”œâ”€â”€ terraform.tfstate.backup
â”‚   â”œâ”€â”€ test_score_local.py
â”‚   â”œâ”€â”€ tfplan
â”‚   â””â”€â”€ versions.tf
â”œâ”€â”€ configs/              # Environment Configs
â”‚   â”œâ”€â”€ dev.env
â”‚   â””â”€â”€ prod.env
â”œâ”€â”€ data/                 # Data Files
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ training_data.jsonl
â”‚   â”‚   â”œâ”€â”€ vector_index.faiss
â”‚   â”‚   â””â”€â”€ vector_index.pkl
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ insurance_terms.pdf
â”‚       â””â”€â”€ vehicle_feedback.csv
â”œâ”€â”€ docs/                 # Documentation
â”‚   â”œâ”€â”€ Architecture.png
â”‚   â””â”€â”€ Project_Doc_1_7.md
â”œâ”€â”€ FastAPI_app/          # FastAPI Application
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ models/               # Model Files
â”‚   â””â”€â”€ huk_distilbert.onnx
â”œâ”€â”€ notebooks/            # Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 01_eda.py
â”œâ”€â”€ reports/              # Reports and Figures
â”‚   â”œâ”€â”€ system_errors.log
â”‚   â””â”€â”€ figures/
â”‚       â”œâ”€â”€ class_balance.png
â”‚       â”œâ”€â”€ confusion_matrix.png
â”‚       â”œâ”€â”€ feedback_by_sentiment_category.png
â”‚       â”œâ”€â”€ feedback_length_distribution.png
â”œâ”€â”€ scripts/              # Utility Scripts
â”‚   â”œâ”€â”€ ingest_data.py
â”‚   â””â”€â”€ setup_models.py
â”œâ”€â”€ src/                  # Source Code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ main_api.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ classifier/
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”œâ”€â”€ export_onnx.py
â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cache.py
â”‚   â”‚   â”œâ”€â”€ engine.py
â”‚   â”‚   â””â”€â”€ vector_store.py
â”‚   â”‚   â””â”€â”€ pii_scrubber.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ logger.py
â”œâ”€â”€ tests/                # Test Suite
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_classifier.py
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â””â”€â”€ test_security.py
â”œâ”€â”€ Security/                # maintenance suite
â”‚   â”œâ”€â”€  __init__.py
â”‚   â”œâ”€â”€ pii_scrubber.py
â”‚   â”œâ”€â”€auth.py
â”œâ”€â”€ score.py    
â”œâ”€â”€ Dockerfile            # Docker Build File
â”œâ”€â”€ README.md             # Project Documentation
â””â”€â”€ requirements.txt      # Python Dependencies
â””â”€â”€ .dockerignore      # Python Dependencies

```bash
# 1. Remove the local Python environment (often the largest culprit)
rm -rf .venv

# 2. Remove cache files
find . -type d -name "__pycache__" -exec rm -rf {} +
rm -rf logs/
rm -rf results/
## ğŸ› ï¸ Step-by-Step: Build & Deploy on AWS
1. **Clone the Repository**
   ```bash
   git clone <your-repo-url>
   cd CC_HD_aws
   ```
2. **Prepare Your Environment**
   - Copy and edit environment files:
     ```bash
     cp configs/dev.env configs/prod.env
     # Edit prod.env with your AWS secrets, keys, and config
     ```

3. **Build the Docker Image**
   - Exclude large files and folders (see .gitignore):
     - `data/` (not needed in Docker if you already have the trained ONNX model)
     - `models/*.onnx` (only include if needed for inference)
     - `reports/`, `results/`, `.venv/`, `__pycache__/`, `*.log`, `*.csv`, `*.pdf`
   - Build the image:
     ```bash
     docker build -t huk-feedback-app .
     ```

4. **Push Docker Image to AWS ECR**
   - Create ECR repository:
     ```bash
     aws ecr create-repository --repository-name huk-feedback-app
     ```
   - Authenticate Docker to ECR:
     ```bash
     aws ecr get-login-password --region <your-region> | docker login --username AWS --password-stdin <aws-account-id>.dkr.ecr.<region>.amazonaws.com
     ```
   - Tag and push:
     ```bash
     docker tag huk-feedback-app:latest <aws-account-id>.dkr.ecr.<region>.amazonaws.com/huk-feedback-app:latest
     docker push <aws-account-id>.dkr.ecr.<region>.amazonaws.com/huk-feedback-app:latest
     ```

5. **Deploy on AWS ECS (Fargate)**
   - Use Terraform or CloudFormation templates in `aws/` to provision ECS Cluster, Task Definition, Service, and Security Group.

6. **Get the Public URL**
   - After deployment, find the Load Balancer DNS name or Service Public IP in the AWS ECS Console.
   - The app runs on port `8000`, so your public URL will look like:
     ```
     http://<your-public-dns>:8000
     ```
   - Test with:
     ```bash
     curl http://<your-public-dns>:8000/docs
     ```
---

## ğŸ§© How the Codebase Fits Together & Design Rationale

This project is architected for real-world production, with each component chosen for a specific reason. Below is an explanation of how the files and modules connect, and why each approach was selected, referencing the ASCII diagram above.

### 1. Security
- **src/security/**: Contains `auth.py` (API key middleware) and `pii_scrubber.py` (removes sensitive data before cloud transfer).
- **Reason**: Protects user data, prevents unauthorized access, and ensures GDPR compliance.

### 2. DevOps & Automation
- **.github/workflows/**: CI/CD pipeline for linting, security scanning, and unit tests.
- **Makefile**: Automates common tasks (train, run, deploy).
- **aws/**: Infrastructure as Code (Terraform, CloudFormation) for reproducible, automated cloud deployments.
- **Reason**: Enables fast, reliable deployments and easy rollback; reduces manual errors.

### 3. Latency & Performance
- **models/huk_distilbert.onnx**: ONNX format for fast, CPU-optimized inference.
- **src/classifier/**: Handles local ML routing for low-latency predictions.
- **src/rag/vector_store.py**: Uses FAISS for fast vector search.
- **Reason**: Minimizes response time for user queries and optimizes resource usage.

### 4. Cost Efficiency
- **src/rag/cache.py**: Semantic caching to avoid repeated expensive OpenAI API calls.
- **ONNX model**: Reduces cloud compute costs by using efficient inference.
- **Reason**: Keeps cloud costs predictable and low, especially at scale.

### 5. Scalability
- **aws/ecs.tf, infrastructure.tf**: ECS Fargate for container orchestration and auto-scaling.
- **src/**: Modular design allows horizontal scaling of API and ML components.
- **Reason**: Supports growth in user traffic and data volume without major redesign.

### 6. Production Readiness
- **src/main_api.py**: FastAPI backend with health checks and request IDs for traceability.
- **configs/prod.env**: Environment separation for secure production deployments.
- **Reason**: Ensures reliability, observability, and maintainability in production.

### 7. Testing & Evaluation
- **tests/**: Pytest-based unit and integration tests for classifier, RAG, and security modules.
- **reports/figures/**: Visualizations (confusion matrix, class balance) for model evaluation.
- **Reason**: Guarantees code quality and model accuracy before deployment.

### 8. Monitoring & Observability
- **src/utils/logger.py**: Centralized JSON logging for performance and error tracking.
- **AWS CloudWatch**: (enabled via ECS) for real-time monitoring and alerting.
- **Reason**: Enables proactive issue detection and system health monitoring.

### 9. User Experience & Accessibility
- **FastAPI auto-generated docs**: Accessible at `/docs` for easy API exploration.
- **Reason**: Makes the system easy to use and test for both developers and stakeholders.
- **Streamlit_/app.py**: Interactive frontend for demo and visualization.

-

**Summary:**
- Every file and module is placed for a reason: security, speed, cost, scalability, and maintainability.
- The architecture supports rapid development, robust production deployment, and easy monitoring/testing.
- The modular design means you can swap out components (e.g., ML model, vector store, cloud provider) with minimal changes.

ğŸ‘¨â€ğŸ’» Autor
Hassan Daoud